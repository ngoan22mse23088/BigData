{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngoan22mse23088/BigData/blob/master/Analyzing_Sales_Data_with_Apache_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1\n",
        "\n",
        "## Set up"
      ],
      "metadata": {
        "id": "afLIVNMoYcjx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQW0uxbm9Ydl"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "nE66eZ3w9d7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Data Preparation:"
      ],
      "metadata": {
        "id": "sNBPTJnYYyeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the sales dataset into Spark RDDs or DataFrames."
      ],
      "metadata": {
        "id": "jOpSa5uZY0Yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d kyanyoga/sample-sales-data\n",
        "\n",
        "!unzip -p \"sample-sales-data.zip\""
      ],
      "metadata": {
        "id": "gwkeBPAh-wNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "c9nvCjnl9cYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext(conf=SparkConf())\n",
        "spark = SparkSession(sparkContext=sc)"
      ],
      "metadata": {
        "id": "e2plNxjK_2_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "print('Pandas version: {}'. format(pd.__version__))"
      ],
      "metadata": {
        "id": "k9eLCVyNAGc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw = spark.read.csv('/content/sales_data_sample.csv', inferSchema=True, header=True)\n",
        "\n",
        "# preview the data\n",
        "# data type\n",
        "print('-'*10, 'data types', '-'*10)\n",
        "pd.DataFrame(data_raw.dtypes)"
      ],
      "metadata": {
        "id": "vhCf_2vh_4Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = data_raw.toPandas()\n",
        "df = raw_df.copy()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MMIIv9YZBjgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data summary\n",
        "print('-'*10, 'data summary', '-'*10)\n",
        "data_raw.describe().toPandas()"
      ],
      "metadata": {
        "id": "Dx5Y0EltANsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view a small subset of the data\n",
        "print('-'*10, 'randomely sample 1% data to view', '-'*10)\n",
        "data_raw.randomSplit([0.01, 0.99])[0].toPandas()"
      ],
      "metadata": {
        "id": "YX7DXNv8ARco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "iOH3asOxAUra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "uSrd_wbDBNMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleanse the data by handling missing values, outliers, or any inconsistencies."
      ],
      "metadata": {
        "id": "uO9pEXnzZBtT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for null values"
      ],
      "metadata": {
        "id": "zTsEWbIqBRLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_null = df.isnull().sum().sort_values(ascending = False)\n",
        "percent_null = (df.isnull().sum()/df.isnull().count()).sort_values(ascending = False)\n",
        "missing_data = pd.concat([total_null,percent_null],axis = 1,keys=['total_null','persent_null'])\n",
        "missing_data"
      ],
      "metadata": {
        "id": "A2xkBwaOBSVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title total_null\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "missing_data['total_null'].plot(kind='hist', bins=20, title='total_null')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "5DJErwQKBvcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping columns"
      ],
      "metadata": {
        "id": "fPfQekhbBx0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing the variables which dont add significant value to the analysis or majority null value.\n",
        "to_drop = ['PHONE','ADDRESSLINE1','ADDRESSLINE2','STATE','POSTALCODE','TERRITORY']\n",
        "df = df.drop(to_drop, axis=1)"
      ],
      "metadata": {
        "id": "1YOw0A8eBtrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for inconsistent data types"
      ],
      "metadata": {
        "id": "6pnR3grHB0bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "kzRJ2XoBBUt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ORDERDATE'] = pd.to_datetime(df['ORDERDATE'])"
      ],
      "metadata": {
        "id": "VT9nogQ7B2co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary stats of Quantitative variables"
      ],
      "metadata": {
        "id": "GDdI-D00B5X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quant_vars = ['QUANTITYORDERED','PRICEEACH','SALES','MSRP']\n",
        "df[quant_vars].describe()"
      ],
      "metadata": {
        "id": "uXemH6fFB4RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(by = ['ORDERDATE'], inplace = True)\n",
        "df.set_index('ORDERDATE', inplace = True)"
      ],
      "metadata": {
        "id": "pthVirDyEr1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "6qfe4Z-TDldI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA - Exploratory Data Analysis and Visualization"
      ],
      "metadata": {
        "id": "3FRVdl12E7Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df.plot(kind='box', subplots=True, sharex=False, sharey=False, figsize=(10,10), layout=(3,4))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g3gCdfHdaiox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_customer = df.groupby(['CUSTOMERNAME']).sum().sort_values('SALES', ascending = False).head(20)\n",
        "top_customer = top_customer[['SALES']].round(3)\n",
        "top_customer.reset_index(inplace = True)"
      ],
      "metadata": {
        "id": "eDrEB7goE6V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,5))\n",
        "plt.title('20 Most Valueable Customer (2003 - 2005)', fontsize = 18)\n",
        "plt.bar(top_customer['CUSTOMERNAME'], top_customer['SALES'], color = '#37C6AB', edgecolor = 'black', linewidth = 1)\n",
        "plt.xlabel('Customer Name', fontsize = 15)\n",
        "plt.ylabel('Revenue', fontsize = 15)\n",
        "plt.xticks(fontsize = 12, rotation = 90)\n",
        "plt.yticks(fontsize = 12)\n",
        "for k, v in top_customer['SALES'].items():\n",
        "    if v > 600000:\n",
        "        plt.text(k, v-270000, '$' + str(v), fontsize = 12, rotation = 90, color = 'black', ha = 'center')\n",
        "    else:\n",
        "        plt.text(k, v+ 50000, '$' + str(v), fontsize = 12, rotation = 90, color = 'black', ha = 'center')"
      ],
      "metadata": {
        "id": "15lVX_JXE9z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_country = df.groupby(['COUNTRY']).sum().sort_values('SALES', ascending = False).head(20)\n",
        "top_country = top_country[['SALES']].round(3)\n",
        "top_country.reset_index(inplace = True)"
      ],
      "metadata": {
        "id": "uMbMfGxoE_BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,5))\n",
        "plt.title('20 Highest Revenue by Country (2003 - 2005)', fontsize = 18)\n",
        "plt.bar(top_country['COUNTRY'], top_country['SALES'], color = '#37C6AB', edgecolor = 'black', linewidth = 1)\n",
        "plt.xlabel('Country', fontsize = 15)\n",
        "plt.ylabel('Revenue', fontsize = 15)\n",
        "plt.xticks(fontsize = 12, rotation = 90)\n",
        "plt.yticks(fontsize = 12)\n",
        "for k, v in top_country['SALES'].items():\n",
        "    if v > 3000000:\n",
        "        plt.text(k, v-1200000, '$' + str(v), fontsize = 12, rotation = 90, color = 'black', ha = 'center')\n",
        "    else:\n",
        "        plt.text(k, v+100000, '$' + str(v), fontsize = 12, rotation = 90, color = 'black', ha = 'center')"
      ],
      "metadata": {
        "id": "jTBK8A28FDUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5RWce30eFEhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find out 20 Highest Revenue by City\n",
        "\n",
        "Then visualized revenue by city. Here are th Top 20 City which generated the highest revenue"
      ],
      "metadata": {
        "id": "EQe6ewtaFGhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_city = df.groupby(['CITY']).sum().sort_values('SALES', ascending = False).head(20)\n",
        "top_city = top_city[['SALES']].round(3)\n",
        "top_city.reset_index(inplace = True)\n",
        "plt.figure(figsize = (15,5))\n",
        "plt.title('20 Highest Revenue by City (2003 - 2005)', fontsize = 18)\n",
        "plt.bar(top_city['CITY'], top_city['SALES'], color = '#37C6AB', edgecolor = 'black', linewidth = 1 )\n",
        "plt.xlabel('City', fontsize = 15)\n",
        "plt.ylabel('Revenue', fontsize = 15)\n",
        "plt.xticks(fontsize = 12, rotation = 90)\n",
        "plt.yticks(fontsize = 12)\n",
        "for k, v, in top_city['SALES'].items():\n",
        "    if v > 800000:\n",
        "        plt.text(k, v-350000, '$' + str(v), fontsize = 12, rotation = 90, color = 'black', ha = 'center')\n",
        "    else:\n",
        "        plt.text(k, v+35000, '$' + str(v), fontsize = 12, rotation = 90, color = 'black', ha = 'center')"
      ],
      "metadata": {
        "id": "BwHnzpVUFHUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_product = df.groupby(['PRODUCTLINE']).sum().sort_values('SALES', ascending = False)\n",
        "top_product = top_product[['SALES']]\n",
        "top_product.reset_index(inplace = True)\n",
        "total_revenue_product = top_product['SALES'].sum()\n",
        "total_revenue_product = str(int(total_revenue_product))\n",
        "total_revenue_product = '$' + total_revenue_product"
      ],
      "metadata": {
        "id": "5cN6slY8FIdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = (13,7)\n",
        "plt.rcParams['font.size'] = 12.0\n",
        "plt.rcParams['font.weight'] = 6\n",
        "def autopct_format(values):\n",
        "    def my_format(pct):\n",
        "        total = sum(values)\n",
        "        val = int(round(pct*total/100.0))\n",
        "        return ' ${v:d}'.format(v = val)\n",
        "    return my_format\n",
        "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99','#55B4B0','#E15D44','#009B77']\n",
        "explode = (0.05,0.05,0.05,0.05,0.05,0.05,0.05)\n",
        "fig1, ax1 = plt.subplots()\n",
        "pie1 = ax1.pie(top_product['SALES'], colors = colors, labels = top_product['PRODUCTLINE'], autopct = autopct_format(top_product['SALES']), startangle = 90, explode = explode)\n",
        "fraction_text_list = pie1[2]\n",
        "for text in fraction_text_list:\n",
        "    text.set_rotation(315)\n",
        "center_circle = plt.Circle((0,0), 0.80, fc = 'white')\n",
        "fig = plt.gcf()\n",
        "fig.gca().add_artist(center_circle)\n",
        "ax1.axis('equal')\n",
        "label = ax1.annotate('Total Revenue \\n' + str(total_revenue_product), color = 'red', xy = (0,0), fontsize = 12, ha  ='center')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FXqIwbNOFNho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "corr_matrix = df.corr()\n",
        "sns.heatmap(corr_matrix, annot = True)"
      ],
      "metadata": {
        "id": "aT0ZG2MrFR5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.tight_layout()\n",
        "sns.barplot(x='PRODUCTLINE',y='SALES',data=df)"
      ],
      "metadata": {
        "id": "0XivoQu9Zipa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(df['STATUS'])"
      ],
      "metadata": {
        "id": "grAhjkdZZmmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "sns.lineplot(x='ORDERDATE', y='SALES', data=df)"
      ],
      "metadata": {
        "id": "kPDQ4rq_XVtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "jnUiI0-UZ1Ca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outlier detection https://www.kaggle.com/code/shohanurrahaman/intro-to-data-science-data-cleaning-02"
      ],
      "metadata": {
        "id": "z6I-UVOUbEVo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8hsxZrh-ewIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df.plot(kind='box', subplots=True, sharex=False, sharey=False, figsize=(10,10), layout=(3,4))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Fb2kNgmaz9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering outlier"
      ],
      "metadata": {
        "id": "PsHDHESdbKn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('original shape of dataset :',df.shape)\n",
        "\n",
        "cols = ['SALES', 'MSRP','QUANTITYORDERED']\n",
        "new_df = df[cols]\n",
        "\n",
        "#calculation\n",
        "Q1 = new_df.quantile(0.25)\n",
        "Q3 = new_df.quantile(0.75)\n",
        "IQR = Q3-Q1\n",
        "maximum = Q3+1.5*IQR\n",
        "minimum = Q1-1.5*IQR\n",
        "#print(minimum)\n",
        "\n",
        "#filter outlier\n",
        "cond = (new_df <= maximum) & (new_df >= minimum)\n",
        "'''\n",
        "we specify that the condition should be true for all three columns by using the all function with axis=1 argument.\n",
        "This gives us a list of True/False against each row.\n",
        "If a row has all three True values, then it gives a True value to that row\n",
        "'''\n",
        "cond = cond.all(axis=1)\n",
        "df = df[cond]\n",
        "print('filtered dataset shape : ',df.shape)\n",
        "\n",
        "#plot again to check that if has any outlier\n",
        "df.plot(kind='box', subplots=True, sharex=False, sharey=False, figsize=(10,10), layout=(3,4))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wKNd_N7TbKXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scatter Plot"
      ],
      "metadata": {
        "id": "E4fn3FthbRJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df[['SALES','QUANTITYORDERED','MSRP']]\n",
        "pd.plotting.scatter_matrix(new_df, figsize = (10,10))"
      ],
      "metadata": {
        "id": "ht7rn9S3bQbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z-Score"
      ],
      "metadata": {
        "id": "dEu67YSybT1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print('shape of original data :',df.shape)\n",
        "\n",
        "mean = new_df['QUANTITYORDERED'].mean()\n",
        "std_dev = new_df['QUANTITYORDERED'].std()\n",
        "\n",
        "# find z scores\n",
        "z_scores = (new_df['QUANTITYORDERED'] - mean) / std_dev\n",
        "z_scores = np.abs(z_scores)\n",
        "\n",
        "#print(z_scores.min())\n",
        "\n",
        "#filter data\n",
        "z_df = new_df[z_scores<3]\n",
        "print('shape of filtered data : ',z_df.shape)\n",
        "\n",
        "#plot data\n",
        "z_df['QUANTITYORDERED'].plot(kind='box')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5AncwSikbXQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Analytics"
      ],
      "metadata": {
        "id": "iNijCpatexUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Order Date Description\\n')\n",
        "\n",
        "df.sort_values(by = ['ORDERDATE'], inplace = True, ascending = True)\n",
        "\n",
        "new_data = pd.DataFrame(df['SALES'])\n",
        "new_data.head()"
      ],
      "metadata": {
        "id": "nmPeglRre2Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title SALES\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "new_data['SALES'].plot(kind='hist', bins=20, title='SALES')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "ZAPxZjSpfUO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.plot()"
      ],
      "metadata": {
        "id": "BhuJjwnHfW63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A series is said to be stationary when its mean and variance do not change over time. From the above distribution of the sales it is not clear whether the sales distribution is stationary or not. Let us perform some stationarity tests to check whether the time series is stationary or not."
      ],
      "metadata": {
        "id": "YWALddOCfcWG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cBOHi2Iofn1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for Stationary"
      ],
      "metadata": {
        "id": "9qh5CHvEferH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = pd.DataFrame(new_data['SALES'].resample('D').mean())\n",
        "new_data = new_data.interpolate(method = 'linear')"
      ],
      "metadata": {
        "id": "b1-4w4tlfh3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 1<br/>\n",
        "\n",
        "To check for stationarity by comparing the change in mean and variance over time, let us split teh data into train, test, and validation"
      ],
      "metadata": {
        "id": "oy9Pqdb4flB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test, validation = np.split(new_data['SALES'].sample(frac = 1), [int(.6*len(new_data['SALES'])), int(.8*len(new_data['SALES']))])"
      ],
      "metadata": {
        "id": "A_7_OCDPfbzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Dataset')\n",
        "print(train)\n",
        "print('Test Dataset')\n",
        "print(test)\n",
        "print('Validation Dataset')\n",
        "print(validation)"
      ],
      "metadata": {
        "id": "0SmYcMh1fY-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above values of mean and variance, it can be inferred that their is not much difference in the three values of mean and variance, indicating that the series is stationary. However, to verify our observations, let us perform a standard stationarity test, called Augmented Dicky Fuller test.\n",
        "\n",
        "Augmented Dicky Fuller Test\n",
        "\n",
        "- The Augmented Dickey-Fuller test is a type of statistical test alsocalled a unit root test.The base of unit root test is that it helps in determining how strongly a time series is defined by a trend.\n",
        "- The null hypothesis of the test is that the time series can be represented by a unit root, that it is not stationary. The alternate hypothesis (rejecting the null hypothesis) is that the time series is stationary.\n",
        "  - Null Hypothesis(H0): Time series is not stationary\n",
        "  - Alternate Hypothesis (H1): Time series is stationary\n",
        "- This result is interpreted using the p-value from the test.\n",
        "  - p-value > 0.05: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n",
        "  - p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary."
      ],
      "metadata": {
        "id": "0YQzeX53fxEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 2 - Augmented Dicky Fuller Test"
      ],
      "metadata": {
        "id": "zOAG_hK3gM4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "#statsmodel provied addfuller()\n",
        "data1 = new_data.iloc[:,0].values\n",
        "adf = adfuller(data1)\n",
        "\n",
        "print(adf)\n",
        "print('\\nADF = ', str(adf[0]))\n",
        "print('\\np-value = ', str(adf[1]))\n",
        "print('\\nCritical Values: ')\n",
        "\n",
        "for key, val in adf[4].items():\n",
        "    print(key,':',val)\n",
        "    if adf[0] < val:\n",
        "        print('Null Hypothesis Rejected. Time Series is Stationary')\n",
        "    else:\n",
        "        print('Null Hypothesis Accepted. Time Series is not Stationary')"
      ],
      "metadata": {
        "id": "duY7ShUPfrgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 20, 10\n",
        "\n",
        "import statsmodels.api as sm\n",
        "decomposition = sm.tsa.seasonal_decompose(new_data, model = 'additive')\n",
        "\n",
        "fig = decomposition.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lQHyYx7ggQyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sales Forecasting using ARIMA"
      ],
      "metadata": {
        "id": "QSxk1ucpgULf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def labelencoder(df):\n",
        "    for c in df.columns:\n",
        "        if df[c].dtype=='object':\n",
        "            df[c] = df[c].fillna('N')\n",
        "            lbl = LabelEncoder()\n",
        "            lbl.fit(list(df[c].values))\n",
        "            df[c] = lbl.transform(df[c].values)\n",
        "    return df"
      ],
      "metadata": {
        "id": "CiBb5iJLgVje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1=labelencoder(df)"
      ],
      "metadata": {
        "id": "FCa0yvFQhDx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target=['PRODUCTLINE']\n",
        "dataY=data1[target]\n",
        "dataX=data1.drop(target,axis=1)"
      ],
      "metadata": {
        "id": "It5b_lQ9hIle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_columns = list(dataX.columns)\n",
        "print(df_columns)"
      ],
      "metadata": {
        "id": "Tqfcwv5fhK7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "m=len(dataX)\n",
        "print(m)\n",
        "M=list(range(m))\n",
        "random.seed(2021)\n",
        "random.shuffle(M)\n",
        "\n",
        "trainX=dataX.iloc[M[0:(m//4)*3]]\n",
        "trainY=dataY.iloc[M[0:(m//4)*3]]\n",
        "testX=dataX.iloc[M[(m//4)*3:]]\n",
        "testY=dataY.iloc[M[(m//4)*3:]]"
      ],
      "metadata": {
        "id": "IJr9PzzHhNTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=trainX\n",
        "test_df=testX"
      ],
      "metadata": {
        "id": "lWyRQDfJhNwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns=df_columns\n",
        "test_df.columns=df_columns"
      ],
      "metadata": {
        "id": "SPrWSxa-hT0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_numeric_feature(input_df):\n",
        "    use_columns = df_columns\n",
        "    return input_df[use_columns].copy()"
      ],
      "metadata": {
        "id": "br-VXjw_hVJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from contextlib import contextmanager\n",
        "from time import time\n",
        "\n",
        "class Timer:\n",
        "    def __init__(self, logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None, sep=' '):\n",
        "\n",
        "        if prefix: format_str = str(prefix) + sep + format_str\n",
        "        if suffix: format_str = format_str + sep + str(suffix)\n",
        "        self.format_str = format_str\n",
        "        self.logger = logger\n",
        "        self.start = None\n",
        "        self.end = None\n",
        "\n",
        "    @property\n",
        "    def duration(self):\n",
        "        if self.end is None:\n",
        "            return 0\n",
        "        return self.end - self.start\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start = time()\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        self.end = time()\n",
        "        out_str = self.format_str.format(self.duration)\n",
        "        if self.logger:\n",
        "            self.logger.info(out_str)\n",
        "        else:\n",
        "            print(out_str)"
      ],
      "metadata": {
        "id": "NGekMpb6hWg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def to_feature(input_df):\n",
        "\n",
        "    processors = [\n",
        "        create_numeric_feature,\n",
        "    ]\n",
        "\n",
        "    out_df = pd.DataFrame()\n",
        "\n",
        "    for func in tqdm(processors, total=len(processors)):\n",
        "        with Timer(prefix='create' + func.__name__ + ' '):\n",
        "            _df = func(input_df)\n",
        "\n",
        "        assert len(_df) == len(input_df), func.__name__\n",
        "        out_df = pd.concat([out_df, _df], axis=1)\n",
        "\n",
        "    return out_df"
      ],
      "metadata": {
        "id": "_aDcG-dXhYZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_feat_df = to_feature(train_df)\n",
        "test_feat_df = to_feature(test_df)"
      ],
      "metadata": {
        "id": "1TwuL3YjhaNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "maObTwf0hdWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from lightgbm import LGBMRegressor, early_stopping\n",
        "\n",
        "def fit_lgbm(X, y, cv,\n",
        "             params: dict=None,\n",
        "             verbose: int=50):\n",
        "\n",
        "    if params is None:\n",
        "        params = {}\n",
        "\n",
        "    models = []\n",
        "    oof_pred = np.zeros_like(y, dtype=np.float)\n",
        "\n",
        "    for i, (idx_train, idx_valid) in enumerate(cv):\n",
        "        x_train, y_train = X[idx_train], y[idx_train]\n",
        "        x_valid, y_valid = X[idx_valid], y[idx_valid]\n",
        "\n",
        "        clf = LGBMRegressor(**params)\n",
        "        early_stopping_callback = early_stopping(stopping_rounds=100)\n",
        "        with Timer(prefix='fit fold={} '.format(i)):\n",
        "            clf.fit(x_train, y_train,\n",
        "                    eval_set=[(x_valid, y_valid)])\n",
        "\n",
        "        pred_i = clf.predict(x_valid)\n",
        "        oof_pred[idx_valid] = pred_i\n",
        "        models.append(clf)\n",
        "        print(f'Fold {i} RMSLE: {mean_squared_error(y_valid, pred_i) ** .5:.4f}')\n",
        "        print()\n",
        "\n",
        "    score = mean_squared_error(y, oof_pred) ** .5\n",
        "    print('-' * 50)\n",
        "    print('FINISHED | Whole RMSLE: {:.4f}'.format(score))\n",
        "    return oof_pred, models"
      ],
      "metadata": {
        "id": "emxqcZ5dhbx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'rmse',\n",
        "    'learning_rate': .1,\n",
        "    'reg_lambda': 1.,\n",
        "    'reg_alpha': .1,\n",
        "    'max_depth': 5,\n",
        "    'n_estimators': 10000,\n",
        "    'colsample_bytree': .5,\n",
        "    'min_child_samples': 10,\n",
        "    'subsample_freq': 3,\n",
        "    'subsample': .9,\n",
        "    'importance_type': 'gain',\n",
        "    'random_state': 71,\n",
        "    'num_leaves': 62\n",
        "}"
      ],
      "metadata": {
        "id": "-9V1rWnphes-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = trainY\n",
        "ydf=pd.DataFrame(y)\n",
        "ydf"
      ],
      "metadata": {
        "id": "SMZMHnvLhhXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title PRODUCTLINE\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "ydf['PRODUCTLINE'].plot(kind='hist', bins=20, title='PRODUCTLINE')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "9m-kz1PThlb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import KFold\n",
        "np.float = float\n",
        "from lightgbm import early_stopping\n",
        "\n",
        "\n",
        "for i in range(1):\n",
        "    fold = KFold(n_splits=5, shuffle=True, random_state=71)\n",
        "    ydfi=ydf.iloc[:,i]\n",
        "    y=np.array(ydfi)\n",
        "    cv = list(fold.split(train_feat_df, y))\n",
        "    oof, models = fit_lgbm(train_feat_df.values, y, cv, params=params, verbose=500)\n",
        "\n",
        "    fig,ax = plt.subplots(figsize=(6,6))\n",
        "    ax.set_title(target[i],fontsize=20)\n",
        "    ax.set_ylabel('predicted',fontsize=12)\n",
        "    ax.set_xlabel('actual',fontsize=12)\n",
        "    ax.scatter(y,oof)"
      ],
      "metadata": {
        "id": "VEUpfCFdhjtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Importance"
      ],
      "metadata": {
        "id": "CP2R-xp9jaG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_importance(models, feat_train_df):\n",
        "\n",
        "    feature_importance_df = pd.DataFrame()\n",
        "    for i, model in enumerate(models):\n",
        "        _df = pd.DataFrame()\n",
        "        _df['feature_importance'] = model.feature_importances_\n",
        "        _df['column'] = feat_train_df.columns\n",
        "        _df['fold'] = i + 1\n",
        "        feature_importance_df = pd.concat([feature_importance_df, _df],\n",
        "                                          axis=0, ignore_index=True)\n",
        "\n",
        "    order = feature_importance_df.groupby('column')\\\n",
        "        .sum()[['feature_importance']]\\\n",
        "        .sort_values('feature_importance', ascending=False).index[:50]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, max(6, len(order) * .25)))\n",
        "    sns.boxenplot(data=feature_importance_df,\n",
        "                  x='feature_importance',\n",
        "                  y='column',\n",
        "                  order=order,\n",
        "                  ax=ax,\n",
        "                  palette='viridis',\n",
        "                  orient='h')\n",
        "\n",
        "    ax.tick_params(axis='x', rotation=0)\n",
        "    #ax.set_title('Importance')\n",
        "    ax.grid()\n",
        "    fig.tight_layout()\n",
        "\n",
        "    return fig,ax\n",
        "\n",
        "#fig, ax = visualize_importance(models, train_feat_df)"
      ],
      "metadata": {
        "id": "9hMkmGzqjKqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1):\n",
        "    fold = KFold(n_splits=5, shuffle=True, random_state=71)\n",
        "    ydfi=ydf.iloc[:,i]\n",
        "    y=np.array(ydfi)\n",
        "    cv = list(fold.split(train_feat_df, y))\n",
        "    oof, models = fit_lgbm(train_feat_df.values, y, cv, params=params, verbose=500)\n",
        "    fig, ax = visualize_importance(models, train_feat_df)\n",
        "    ax.set_title(target[i]+' Imortance',fontsize=20)"
      ],
      "metadata": {
        "id": "j3E92rpljd-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds=[]\n",
        "for i in range(5):\n",
        "    preds += [models[i].predict(test_feat_df.values)/5]\n",
        "predsT=np.array(preds).T\n",
        "preds2=[]\n",
        "for item in predsT:\n",
        "    value=sum(item)\n",
        "    preds2+=[value]\n",
        "print(preds2[0:5])"
      ],
      "metadata": {
        "id": "dY7g_FVxjg9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1):\n",
        "    fig, ax = plt.subplots(figsize=(10,5))\n",
        "    sns.histplot(oof, label='Train Predicted '+target[i], ax=ax, color='C1',bins=30)\n",
        "    sns.histplot(preds2, label='Test Predicted '+target[i], ax=ax, color='black',bins=30)\n",
        "    ax.legend()\n",
        "    ax.grid()"
      ],
      "metadata": {
        "id": "2jB6HlLQjiEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true=testY\n",
        "y_pred=pd.Series(preds2).apply(lambda x: round(x,0))"
      ],
      "metadata": {
        "id": "YzjPw526jj9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3sOpV-Sj79W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title ORDERNUMBER\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "df['ORDERNUMBER'].plot(kind='hist', bins=20, title='ORDERNUMBER')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "zeA2zhwDkgct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred, target_names=raw_df['PRODUCTLINE'].unique().tolist(), digits=4))"
      ],
      "metadata": {
        "id": "nue507CcjlWq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}